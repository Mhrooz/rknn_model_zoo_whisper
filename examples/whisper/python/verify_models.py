#!/usr/bin/env python3
"""
éªŒè¯ Whisper Encoder å’Œ Decoder æ¨¡å‹æ˜¯å¦æ­£å¸¸å·¥ä½œ

ä½¿ç”¨æ–¹æ³•:
  PC ä¸Š:   python verify_models.py --check-only    (åªæ£€æŸ¥æ–‡ä»¶ï¼Œä¸æ¨ç†)
  æ¿ä¸Š:    python verify_models.py                  (å®é™…æ¨ç†æµ‹è¯•)
"""

import numpy as np
import sys
import os
import argparse
import platform

# æ£€æŸ¥æ˜¯å¦åœ¨ ARM æ¿ä¸Š
def is_arm_board():
    machine = platform.machine().lower()
    return 'arm' in machine or 'aarch64' in machine

# æ£€æŸ¥æ˜¯å¦æœ‰ rknn-toolkit2 æˆ– rknn-toolkit-lite2
try:
    from rknnlite.api import RKNNLite
    HAS_RKNN_LITE = True
    HAS_RKNN = False
    print("âœ… ä½¿ç”¨ rknn-toolkit-lite2 (æ¿ä¸Šæ¨ç†)")
except ImportError:
    HAS_RKNN_LITE = False
    try:
        from rknn.api import RKNN
        HAS_RKNN = True
        print("âœ… ä½¿ç”¨ rknn-toolkit2 (æ¨¡å‹è½¬æ¢å·¥å…·)")
    except ImportError:
        HAS_RKNN = False


def check_model_file(model_path, model_name):
    """åªæ£€æŸ¥æ¨¡å‹æ–‡ä»¶ï¼ˆä¸æ¨ç†ï¼‰"""
    print(f"\næ£€æŸ¥ {model_name} æ¨¡å‹æ–‡ä»¶...")
    
    if not os.path.exists(model_path):
        print(f"  âŒ æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return False
    
    file_size = os.path.getsize(model_path)
    file_size_mb = file_size / (1024 * 1024)
    print(f"  ğŸ“ æ–‡ä»¶è·¯å¾„: {model_path}")
    print(f"  ğŸ“Š æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")
    
    # æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦åˆç†
    if file_size < 1024 * 1024:  # < 1MB
        print(f"  âš ï¸  è­¦å‘Š: æ–‡ä»¶å¤ªå° ({file_size_mb:.2f} MB)ï¼Œå¯èƒ½æŸå")
        return False
    
    # è¯»å–æ–‡ä»¶å¤´æ£€æŸ¥æ˜¯å¦æ˜¯ RKNN æ ¼å¼
    try:
        with open(model_path, 'rb') as f:
            header = f.read(4)
            if header[:4] == b'RKNN':
                print(f"  âœ… æ–‡ä»¶æ ¼å¼æ­£ç¡® (RKNN)")
            else:
                print(f"  âš ï¸  è­¦å‘Š: æ–‡ä»¶å¤´ä¸æ˜¯ RKNN æ ¼å¼")
                return False
    except Exception as e:
        print(f"  âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return False
    
    print(f"  âœ… {model_name} æ–‡ä»¶æ£€æŸ¥é€šè¿‡")
    return True


def test_encoder(model_path, check_only=False):
    """æµ‹è¯• Encoder æ¨¡å‹"""
    print("\n" + "="*60)
    print("æµ‹è¯• Encoder æ¨¡å‹")
    print("="*60)
    
    if check_only:
        return check_model_file(model_path, "Encoder")
    
    if not HAS_RKNN_LITE and not HAS_RKNN:
        print("âŒ æœªå®‰è£… rknn-toolkit-lite2 æˆ– rknn-toolkit2")
        print("   æ¿ä¸Šæ¨ç†éœ€è¦: pip install rknnlite")
        print("   æˆ–ä½¿ç”¨ --check-only æ¨¡å¼")
        return False
    
    # ä¼˜å…ˆä½¿ç”¨ rknn-lite (æ¿ä¸Šæ¨ç†)
    use_lite = HAS_RKNN_LITE and is_arm_board()
    
    if not use_lite and not is_arm_board():
        print("âš ï¸  è­¦å‘Š: ä¸åœ¨ ARM æ¿ä¸Šï¼ŒRKNN æ¨ç†å¯èƒ½å¤±è´¥")
        print("   å»ºè®®ä½¿ç”¨ --check-only æ¨¡å¼æˆ–åœ¨å¼€å‘æ¿ä¸Šè¿è¡Œ")
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return False
    
    print(f"åŠ è½½æ¨¡å‹: {model_path}")
    
    if use_lite:
        from rknnlite.api import RKNNLite
        rknn = RKNNLite()
        print("ä½¿ç”¨ RKNNLite (æ¿ä¸Š NPU æ¨ç†)")
    else:
        from rknn.api import RKNN
        rknn = RKNN(verbose=False)
        print("ä½¿ç”¨ RKNN (æ¨¡æ‹Ÿå™¨/è½¬æ¢å·¥å…·)")
    
    ret = rknn.load_rknn(model_path)
    if ret != 0:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {ret}")
        return False
    
    print("åˆå§‹åŒ–è¿è¡Œæ—¶ç¯å¢ƒ...")
    if use_lite:
        # RKNNLite ç›´æ¥åˆå§‹åŒ–ï¼Œä¼šä½¿ç”¨ NPU
        ret = rknn.init_runtime()
    else:
        # RKNN éœ€è¦æŒ‡å®š target (ä½†åœ¨ PC ä¸Šä¼šå¤±è´¥)
        ret = rknn.init_runtime()
    
    if ret != 0:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {ret}")
        rknn.release()
        return False
    
    # åˆ›å»ºæ¨¡æ‹Ÿè¾“å…¥ (mel features: 1 x 80 x 3000)
    print("\nåˆ›å»ºæµ‹è¯•è¾“å…¥ (1, 80, 3000) - æ¨¡æ‹Ÿ 30 ç§’éŸ³é¢‘çš„ mel ç‰¹å¾")
    mel_input = np.random.randn(1, 80, 3000).astype(np.float32)
    print(f"  è¾“å…¥å½¢çŠ¶: {mel_input.shape}")
    print(f"  è¾“å…¥èŒƒå›´: [{mel_input.min():.3f}, {mel_input.max():.3f}]")
    print(f"  è¾“å…¥å‡å€¼: {mel_input.mean():.6f}")
    
    print("\næ‰§è¡Œæ¨ç†...")
    outputs = rknn.inference(inputs=[mel_input])
    
    if outputs is None or len(outputs) == 0:
        print("âŒ æ¨ç†å¤±è´¥: æ²¡æœ‰è¾“å‡º")
        rknn.release()
        return False
    
    encoder_out = outputs[0]
    
    print("\nğŸ“Š Encoder è¾“å‡ºåˆ†æ:")
    print(f"  è¾“å‡ºå½¢çŠ¶: {encoder_out.shape}")
    expected_shape = (1, 1500, 512)  # 30ç§’éŸ³é¢‘
    if encoder_out.shape != expected_shape:
        print(f"  âš ï¸  è­¦å‘Š: é¢„æœŸå½¢çŠ¶ {expected_shape}, å®é™… {encoder_out.shape}")
    
    print(f"  æ•°æ®ç±»å‹: {encoder_out.dtype}")
    print(f"  å€¼èŒƒå›´: [{encoder_out.min():.6f}, {encoder_out.max():.6f}]")
    print(f"  å‡å€¼: {encoder_out.mean():.6f}")
    print(f"  æ ‡å‡†å·®: {encoder_out.std():.6f}")
    
    # æ£€æŸ¥å‰ 10 ä¸ªå€¼
    flat = encoder_out.flatten()
    print(f"  å‰ 10 ä¸ªå€¼: {flat[:10]}")
    
    # æ£€æŸ¥æ˜¯å¦å¼‚å¸¸
    issues = []
    
    if np.all(encoder_out == 0):
        issues.append("âŒ æ‰€æœ‰è¾“å‡ºå€¼éƒ½æ˜¯ 0")
    
    if np.isnan(encoder_out).any():
        issues.append(f"âŒ åŒ…å« NaN å€¼: {np.isnan(encoder_out).sum()} ä¸ª")
    
    if np.isinf(encoder_out).any():
        issues.append(f"âŒ åŒ…å« Inf å€¼: {np.isinf(encoder_out).sum()} ä¸ª")
    
    if abs(encoder_out.mean()) > 100:
        issues.append(f"âš ï¸  å‡å€¼è¿‡å¤§: {encoder_out.mean():.3f}")
    
    if encoder_out.std() < 0.01:
        issues.append(f"âš ï¸  æ ‡å‡†å·®è¿‡å° (å¯èƒ½é‡åŒ–å¤±è´¥): {encoder_out.std():.6f}")
    
    if issues:
        print("\né—®é¢˜æ£€æµ‹:")
        for issue in issues:
            print(f"  {issue}")
        result = False
    else:
        print("\nâœ… Encoder è¾“å‡ºçœ‹èµ·æ¥æ­£å¸¸")
        result = True
    
    rknn.release()
    return result


def test_decoder(model_path, check_only=False):
    """æµ‹è¯• Decoder æ¨¡å‹"""
    print("\n" + "="*60)
    print("æµ‹è¯• Decoder æ¨¡å‹")
    print("="*60)
    
    if check_only:
        return check_model_file(model_path, "Decoder")
    
    if not HAS_RKNN_LITE and not HAS_RKNN:
        print("âŒ æœªå®‰è£… rknn-toolkit-lite2 æˆ– rknn-toolkit2")
        print("   æ¿ä¸Šæ¨ç†éœ€è¦: pip install rknnlite")
        print("   æˆ–ä½¿ç”¨ --check-only æ¨¡å¼")
        return False
    
    # ä¼˜å…ˆä½¿ç”¨ rknn-lite (æ¿ä¸Šæ¨ç†)
    use_lite = HAS_RKNN_LITE and is_arm_board()
    
    if not use_lite and not is_arm_board():
        print("âš ï¸  è­¦å‘Š: ä¸åœ¨ ARM æ¿ä¸Šï¼ŒRKNN æ¨ç†å¯èƒ½å¤±è´¥")
        print("   å»ºè®®ä½¿ç”¨ --check-only æ¨¡å¼æˆ–åœ¨å¼€å‘æ¿ä¸Šè¿è¡Œ")
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return False
    
    print(f"åŠ è½½æ¨¡å‹: {model_path}")
    
    if use_lite:
        from rknnlite.api import RKNNLite
        rknn = RKNNLite()
        print("ä½¿ç”¨ RKNNLite (æ¿ä¸Š NPU æ¨ç†)")
    else:
        from rknn.api import RKNN
        rknn = RKNN(verbose=False)
        print("ä½¿ç”¨ RKNN (æ¨¡æ‹Ÿå™¨/è½¬æ¢å·¥å…·)")
    
    ret = rknn.load_rknn(model_path)
    if ret != 0:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {ret}")
        return False
    
    print("åˆå§‹åŒ–è¿è¡Œæ—¶ç¯å¢ƒ...")
    if use_lite:
        # RKNNLite ç›´æ¥åˆå§‹åŒ–ï¼Œä¼šä½¿ç”¨ NPU
        ret = rknn.init_runtime()
    else:
        # RKNN éœ€è¦æŒ‡å®š target (ä½†åœ¨ PC ä¸Šä¼šå¤±è´¥)
        ret = rknn.init_runtime()
    
    if ret != 0:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {ret}")
        rknn.release()
        return False
    
    # åˆ›å»ºæ¨¡æ‹Ÿè¾“å…¥
    print("\nåˆ›å»ºæµ‹è¯•è¾“å…¥:")
    print("  Encoder è¾“å‡º: (1, 1500, 512)")
    encoder_out = np.random.randn(1, 1500, 512).astype(np.float32)
    
    print("  Token åºåˆ—: (1, 4) - [50258, 50259, 50360, 1220]")
    # 50258: <|startoftranscript|>
    # 50259: <|en|>
    # 50360: <|transcribe|>
    # 1220: éšæœº token
    tokens = np.array([[50258, 50259, 50360, 1220]], dtype=np.int32)
    
    print("\næ‰§è¡Œæ¨ç†...")
    outputs = rknn.inference(inputs=[encoder_out, tokens])
    
    if outputs is None or len(outputs) == 0:
        print("âŒ æ¨ç†å¤±è´¥: æ²¡æœ‰è¾“å‡º")
        rknn.release()
        return False
    
    logits = outputs[0]
    
    print("\nğŸ“Š Decoder è¾“å‡ºåˆ†æ:")
    print(f"  è¾“å‡ºå½¢çŠ¶: {logits.shape}")
    expected_shape = (1, 4, 51865)  # vocab size
    if logits.shape != expected_shape:
        print(f"  âš ï¸  è­¦å‘Š: é¢„æœŸå½¢çŠ¶ {expected_shape}, å®é™… {logits.shape}")
    
    print(f"  æ•°æ®ç±»å‹: {logits.dtype}")
    print(f"  Logits èŒƒå›´: [{logits.min():.3f}, {logits.max():.3f}]")
    
    # åˆ†ææœ€åä¸€ä¸ª token çš„é¢„æµ‹
    last_logits = logits[0, -1, :]
    top5_indices = np.argsort(last_logits)[-5:][::-1]
    top5_values = last_logits[top5_indices]
    
    print(f"\n  æœ€åä¸€ä¸ª token ä½ç½®çš„ Top-5 é¢„æµ‹:")
    for i, (idx, val) in enumerate(zip(top5_indices, top5_values), 1):
        print(f"    {i}. Token {idx}: logit={val:.3f}")
    
    # æ£€æŸ¥æ˜¯å¦å¼‚å¸¸
    issues = []
    
    if np.all(logits == 0):
        issues.append("âŒ æ‰€æœ‰ logits éƒ½æ˜¯ 0")
    
    if np.isnan(logits).any():
        issues.append(f"âŒ åŒ…å« NaN å€¼: {np.isnan(logits).sum()} ä¸ª")
    
    if np.isinf(logits).any():
        issues.append(f"âŒ åŒ…å« Inf å€¼: {np.isinf(logits).sum()} ä¸ª")
    
    # æ£€æŸ¥æ˜¯å¦æ€»æ˜¯é¢„æµ‹ EOS
    EOS_TOKEN = 50257
    if top5_indices[0] == EOS_TOKEN:
        issues.append(f"âš ï¸  æœ€é«˜æ¦‚ç‡æ˜¯ EOS token ({EOS_TOKEN}) - å¯èƒ½å¯¼è‡´ç©ºè¾“å‡º")
    
    # æ£€æŸ¥æ¦‚ç‡åˆ†å¸ƒæ˜¯å¦å¤ªå¹³å¦
    if logits.std() < 0.1:
        issues.append(f"âš ï¸  Logits æ ‡å‡†å·®è¿‡å° (åˆ†å¸ƒå¤ªå¹³å¦): {logits.std():.6f}")
    
    if issues:
        print("\né—®é¢˜æ£€æµ‹:")
        for issue in issues:
            print(f"  {issue}")
        result = False
    else:
        print("\nâœ… Decoder è¾“å‡ºçœ‹èµ·æ¥æ­£å¸¸")
        result = True
    
    rknn.release()
    return result


def main():
    parser = argparse.ArgumentParser(
        description='éªŒè¯ Whisper RKNN æ¨¡å‹',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # PC ä¸Šåªæ£€æŸ¥æ–‡ä»¶ï¼ˆæ¨èï¼‰
  python verify_models.py --check-only
  
  # å¼€å‘æ¿ä¸Šå®é™…æ¨ç†æµ‹è¯•
  python verify_models.py
  
  # æŒ‡å®šæ¨¡å‹è·¯å¾„
  python verify_models.py --encoder model/encoder.rknn --decoder model/decoder.rknn --check-only
        """
    )
    parser.add_argument('--check-only', action='store_true',
                        help='ä»…æ£€æŸ¥æ¨¡å‹æ–‡ä»¶ï¼Œä¸æ‰§è¡Œæ¨ç†ï¼ˆPC ä¸Šä½¿ç”¨ï¼‰')
    parser.add_argument('--encoder', default='model/whisper_encoder_base_i8_2.rknn',
                        help='Encoder æ¨¡å‹è·¯å¾„')
    parser.add_argument('--decoder', default='model/whisper_decoder_base_i8.rknn',
                        help='Decoder æ¨¡å‹è·¯å¾„')
    
    args = parser.parse_args()
    
    print("="*60)
    print("Whisper æ¨¡å‹éªŒè¯å·¥å…·")
    print("="*60)
    
    if args.check_only:
        print("\næ¨¡å¼: ä»…æ£€æŸ¥æ–‡ä»¶ï¼ˆä¸æ¨ç†ï¼‰")
    else:
        print("\næ¨¡å¼: å®Œæ•´æµ‹è¯•ï¼ˆæ¨ç†éªŒè¯ï¼‰")
        if not is_arm_board():
            print("\nâš ï¸  æ£€æµ‹åˆ°é ARM ç¯å¢ƒ")
            print("RKNN æ¨¡å‹åªèƒ½åœ¨å¼€å‘æ¿ä¸Šæ¨ç†")
            print("å»ºè®®ä½¿ç”¨: python verify_models.py --check-only")
            response = input("\nç»§ç»­å°è¯•æ¨ç†? (y/N): ")
            if response.lower() != 'y':
                print("å·²å–æ¶ˆ")
                return 0
    
    if not HAS_RKNN and not args.check_only:
        print("\nâŒ é”™è¯¯: æœªå®‰è£… rknn-toolkit2")
        print("å®‰è£…: pip install rknn-toolkit2")
        print("æˆ–ä½¿ç”¨: python verify_models.py --check-only")
        return 1
    
    # æµ‹è¯• Encoder
    encoder_ok = test_encoder(args.encoder, args.check_only)
    
    # æµ‹è¯• Decoder
    decoder_ok = test_decoder(args.decoder, args.check_only)
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    print(f"Encoder: {'âœ… é€šè¿‡' if encoder_ok else 'âŒ å¤±è´¥'}")
    print(f"Decoder: {'âœ… é€šè¿‡' if decoder_ok else 'âŒ å¤±è´¥'}")
    
    if not encoder_ok:
        print("\nğŸ” Encoder é—®é¢˜å¯èƒ½åŸå› :")
        print("  1. é‡åŒ–é…ç½®ä¸å½“ï¼ˆmean_values, std_values é”™è¯¯ï¼‰")
        print("  2. è¾“å…¥æ•°æ®é¢„å¤„ç†é—®é¢˜")
        print("  3. æ¨¡å‹è½¬æ¢æ—¶å‡ºé”™")
        print("\nå»ºè®®:")
        print("  - æ£€æŸ¥é‡åŒ–æ—¶çš„ mean_values å’Œ std_values")
        print("  - å°è¯•ä½¿ç”¨ FP16 æˆ–æ··åˆé‡åŒ–")
        print("  - å¢åŠ æ ¡å‡†æ•°æ®çš„å¤šæ ·æ€§")
    
    if not decoder_ok:
        print("\nğŸ” Decoder é—®é¢˜å¯èƒ½åŸå› :")
        print("  1. æ ¡å‡†æ•°æ®ä¸æ­£ç¡®ï¼ˆencoder è¾“å‡ºè´¨é‡å·®ï¼‰")
        print("  2. Token embedding é‡åŒ–å¤±è´¥")
        print("  3. è¯æ±‡è¡¨æˆ– token é…ç½®é”™è¯¯")
        print("\nå»ºè®®:")
        print("  - ç¡®è®¤ encoder_dumps/*.bin æ–‡ä»¶æ­£å¸¸")
        print("  - æ£€æŸ¥ bin_to_decoder_dataset.py è½¬æ¢æ˜¯å¦æ­£ç¡®")
        print("  - éªŒè¯ decoder é‡åŒ–é…ç½®")
    
    if encoder_ok and decoder_ok:
        print("\nâœ… ä¸¤ä¸ªæ¨¡å‹éƒ½é€šè¿‡äº†åŸºæœ¬éªŒè¯")
        print("\nå¦‚æœå®é™…æ¨ç†ä»è¾“å‡ºä¸ºç©ºï¼Œæ£€æŸ¥:")
        print("  1. éŸ³é¢‘é¢„å¤„ç†ï¼ˆmel ç‰¹å¾æå–ï¼‰")
        print("  2. Token è§£ç é€»è¾‘")
        print("  3. è¯æ±‡è¡¨åŠ è½½")
        print("  4. åå¤„ç†æ­¥éª¤")
    
    print("\n" + "="*60)
    
    return 0 if (encoder_ok and decoder_ok) else 1


if __name__ == "__main__":
    sys.exit(main())
