#!/usr/bin/env python3
"""
éªŒè¯ Whisper Encoder å’Œ Decoder æ¨¡å‹æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import numpy as np
import sys
import os

# æ£€æŸ¥æ˜¯å¦æœ‰ rknn-toolkit2
try:
    from rknn.api import RKNN
    print("âœ… rknn-toolkit2 å·²å®‰è£…")
except ImportError:
    print("âŒ é”™è¯¯: éœ€è¦å®‰è£… rknn-toolkit2")
    print("   pip install rknn-toolkit2")
    sys.exit(1)


def test_encoder(model_path):
    """æµ‹è¯• Encoder æ¨¡å‹"""
    print("\n" + "="*60)
    print("æµ‹è¯• Encoder æ¨¡å‹")
    print("="*60)
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return False
    
    print(f"åŠ è½½æ¨¡å‹: {model_path}")
    rknn = RKNN(verbose=False)
    
    ret = rknn.load_rknn(model_path)
    if ret != 0:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {ret}")
        return False
    
    print("åˆå§‹åŒ–è¿è¡Œæ—¶ç¯å¢ƒ...")
    ret = rknn.init_runtime()
    if ret != 0:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {ret}")
        rknn.release()
        return False
    
    # åˆ›å»ºæ¨¡æ‹Ÿè¾“å…¥ (mel features: 1 x 80 x 3000)
    print("\nåˆ›å»ºæµ‹è¯•è¾“å…¥ (1, 80, 3000) - æ¨¡æ‹Ÿ 30 ç§’éŸ³é¢‘çš„ mel ç‰¹å¾")
    mel_input = np.random.randn(1, 80, 3000).astype(np.float32)
    print(f"  è¾“å…¥å½¢çŠ¶: {mel_input.shape}")
    print(f"  è¾“å…¥èŒƒå›´: [{mel_input.min():.3f}, {mel_input.max():.3f}]")
    print(f"  è¾“å…¥å‡å€¼: {mel_input.mean():.6f}")
    
    print("\næ‰§è¡Œæ¨ç†...")
    outputs = rknn.inference(inputs=[mel_input])
    
    if outputs is None or len(outputs) == 0:
        print("âŒ æ¨ç†å¤±è´¥: æ²¡æœ‰è¾“å‡º")
        rknn.release()
        return False
    
    encoder_out = outputs[0]
    
    print("\nğŸ“Š Encoder è¾“å‡ºåˆ†æ:")
    print(f"  è¾“å‡ºå½¢çŠ¶: {encoder_out.shape}")
    expected_shape = (1, 1500, 512)  # 30ç§’éŸ³é¢‘
    if encoder_out.shape != expected_shape:
        print(f"  âš ï¸  è­¦å‘Š: é¢„æœŸå½¢çŠ¶ {expected_shape}, å®é™… {encoder_out.shape}")
    
    print(f"  æ•°æ®ç±»å‹: {encoder_out.dtype}")
    print(f"  å€¼èŒƒå›´: [{encoder_out.min():.6f}, {encoder_out.max():.6f}]")
    print(f"  å‡å€¼: {encoder_out.mean():.6f}")
    print(f"  æ ‡å‡†å·®: {encoder_out.std():.6f}")
    
    # æ£€æŸ¥å‰ 10 ä¸ªå€¼
    flat = encoder_out.flatten()
    print(f"  å‰ 10 ä¸ªå€¼: {flat[:10]}")
    
    # æ£€æŸ¥æ˜¯å¦å¼‚å¸¸
    issues = []
    
    if np.all(encoder_out == 0):
        issues.append("âŒ æ‰€æœ‰è¾“å‡ºå€¼éƒ½æ˜¯ 0")
    
    if np.isnan(encoder_out).any():
        issues.append(f"âŒ åŒ…å« NaN å€¼: {np.isnan(encoder_out).sum()} ä¸ª")
    
    if np.isinf(encoder_out).any():
        issues.append(f"âŒ åŒ…å« Inf å€¼: {np.isinf(encoder_out).sum()} ä¸ª")
    
    if abs(encoder_out.mean()) > 100:
        issues.append(f"âš ï¸  å‡å€¼è¿‡å¤§: {encoder_out.mean():.3f}")
    
    if encoder_out.std() < 0.01:
        issues.append(f"âš ï¸  æ ‡å‡†å·®è¿‡å° (å¯èƒ½é‡åŒ–å¤±è´¥): {encoder_out.std():.6f}")
    
    if issues:
        print("\né—®é¢˜æ£€æµ‹:")
        for issue in issues:
            print(f"  {issue}")
        result = False
    else:
        print("\nâœ… Encoder è¾“å‡ºçœ‹èµ·æ¥æ­£å¸¸")
        result = True
    
    rknn.release()
    return result


def test_decoder(model_path):
    """æµ‹è¯• Decoder æ¨¡å‹"""
    print("\n" + "="*60)
    print("æµ‹è¯• Decoder æ¨¡å‹")
    print("="*60)
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return False
    
    print(f"åŠ è½½æ¨¡å‹: {model_path}")
    rknn = RKNN(verbose=False)
    
    ret = rknn.load_rknn(model_path)
    if ret != 0:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {ret}")
        return False
    
    print("åˆå§‹åŒ–è¿è¡Œæ—¶ç¯å¢ƒ...")
    ret = rknn.init_runtime()
    if ret != 0:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {ret}")
        rknn.release()
        return False
    
    # åˆ›å»ºæ¨¡æ‹Ÿè¾“å…¥
    print("\nåˆ›å»ºæµ‹è¯•è¾“å…¥:")
    print("  Encoder è¾“å‡º: (1, 1500, 512)")
    encoder_out = np.random.randn(1, 1500, 512).astype(np.float32)
    
    print("  Token åºåˆ—: (1, 4) - [50258, 50259, 50360, 1220]")
    # 50258: <|startoftranscript|>
    # 50259: <|en|>
    # 50360: <|transcribe|>
    # 1220: éšæœº token
    tokens = np.array([[50258, 50259, 50360, 1220]], dtype=np.int32)
    
    print("\næ‰§è¡Œæ¨ç†...")
    outputs = rknn.inference(inputs=[encoder_out, tokens])
    
    if outputs is None or len(outputs) == 0:
        print("âŒ æ¨ç†å¤±è´¥: æ²¡æœ‰è¾“å‡º")
        rknn.release()
        return False
    
    logits = outputs[0]
    
    print("\nğŸ“Š Decoder è¾“å‡ºåˆ†æ:")
    print(f"  è¾“å‡ºå½¢çŠ¶: {logits.shape}")
    expected_shape = (1, 4, 51865)  # vocab size
    if logits.shape != expected_shape:
        print(f"  âš ï¸  è­¦å‘Š: é¢„æœŸå½¢çŠ¶ {expected_shape}, å®é™… {logits.shape}")
    
    print(f"  æ•°æ®ç±»å‹: {logits.dtype}")
    print(f"  Logits èŒƒå›´: [{logits.min():.3f}, {logits.max():.3f}]")
    
    # åˆ†ææœ€åä¸€ä¸ª token çš„é¢„æµ‹
    last_logits = logits[0, -1, :]
    top5_indices = np.argsort(last_logits)[-5:][::-1]
    top5_values = last_logits[top5_indices]
    
    print(f"\n  æœ€åä¸€ä¸ª token ä½ç½®çš„ Top-5 é¢„æµ‹:")
    for i, (idx, val) in enumerate(zip(top5_indices, top5_values), 1):
        print(f"    {i}. Token {idx}: logit={val:.3f}")
    
    # æ£€æŸ¥æ˜¯å¦å¼‚å¸¸
    issues = []
    
    if np.all(logits == 0):
        issues.append("âŒ æ‰€æœ‰ logits éƒ½æ˜¯ 0")
    
    if np.isnan(logits).any():
        issues.append(f"âŒ åŒ…å« NaN å€¼: {np.isnan(logits).sum()} ä¸ª")
    
    if np.isinf(logits).any():
        issues.append(f"âŒ åŒ…å« Inf å€¼: {np.isinf(logits).sum()} ä¸ª")
    
    # æ£€æŸ¥æ˜¯å¦æ€»æ˜¯é¢„æµ‹ EOS
    EOS_TOKEN = 50257
    if top5_indices[0] == EOS_TOKEN:
        issues.append(f"âš ï¸  æœ€é«˜æ¦‚ç‡æ˜¯ EOS token ({EOS_TOKEN}) - å¯èƒ½å¯¼è‡´ç©ºè¾“å‡º")
    
    # æ£€æŸ¥æ¦‚ç‡åˆ†å¸ƒæ˜¯å¦å¤ªå¹³å¦
    if logits.std() < 0.1:
        issues.append(f"âš ï¸  Logits æ ‡å‡†å·®è¿‡å° (åˆ†å¸ƒå¤ªå¹³å¦): {logits.std():.6f}")
    
    if issues:
        print("\né—®é¢˜æ£€æµ‹:")
        for issue in issues:
            print(f"  {issue}")
        result = False
    else:
        print("\nâœ… Decoder è¾“å‡ºçœ‹èµ·æ¥æ­£å¸¸")
        result = True
    
    rknn.release()
    return result


def main():
    print("="*60)
    print("Whisper æ¨¡å‹éªŒè¯å·¥å…·")
    print("="*60)
    
    # æ¨¡å‹è·¯å¾„
    encoder_path = "model/whisper_encoder_base_i8_2.rknn"
    decoder_path = "model/whisper_decoder_base_i8.rknn"
    
    # æµ‹è¯• Encoder
    encoder_ok = test_encoder(encoder_path)
    
    # æµ‹è¯• Decoder
    decoder_ok = test_decoder(decoder_path)
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    print(f"Encoder: {'âœ… é€šè¿‡' if encoder_ok else 'âŒ å¤±è´¥'}")
    print(f"Decoder: {'âœ… é€šè¿‡' if decoder_ok else 'âŒ å¤±è´¥'}")
    
    if not encoder_ok:
        print("\nğŸ” Encoder é—®é¢˜å¯èƒ½åŸå› :")
        print("  1. é‡åŒ–é…ç½®ä¸å½“ï¼ˆmean_values, std_values é”™è¯¯ï¼‰")
        print("  2. è¾“å…¥æ•°æ®é¢„å¤„ç†é—®é¢˜")
        print("  3. æ¨¡å‹è½¬æ¢æ—¶å‡ºé”™")
        print("\nå»ºè®®:")
        print("  - æ£€æŸ¥é‡åŒ–æ—¶çš„ mean_values å’Œ std_values")
        print("  - å°è¯•ä½¿ç”¨ FP16 æˆ–æ··åˆé‡åŒ–")
        print("  - å¢åŠ æ ¡å‡†æ•°æ®çš„å¤šæ ·æ€§")
    
    if not decoder_ok:
        print("\nğŸ” Decoder é—®é¢˜å¯èƒ½åŸå› :")
        print("  1. æ ¡å‡†æ•°æ®ä¸æ­£ç¡®ï¼ˆencoder è¾“å‡ºè´¨é‡å·®ï¼‰")
        print("  2. Token embedding é‡åŒ–å¤±è´¥")
        print("  3. è¯æ±‡è¡¨æˆ– token é…ç½®é”™è¯¯")
        print("\nå»ºè®®:")
        print("  - ç¡®è®¤ encoder_dumps/*.bin æ–‡ä»¶æ­£å¸¸")
        print("  - æ£€æŸ¥ bin_to_decoder_dataset.py è½¬æ¢æ˜¯å¦æ­£ç¡®")
        print("  - éªŒè¯ decoder é‡åŒ–é…ç½®")
    
    if encoder_ok and decoder_ok:
        print("\nâœ… ä¸¤ä¸ªæ¨¡å‹éƒ½é€šè¿‡äº†åŸºæœ¬éªŒè¯")
        print("\nå¦‚æœå®é™…æ¨ç†ä»è¾“å‡ºä¸ºç©ºï¼Œæ£€æŸ¥:")
        print("  1. éŸ³é¢‘é¢„å¤„ç†ï¼ˆmel ç‰¹å¾æå–ï¼‰")
        print("  2. Token è§£ç é€»è¾‘")
        print("  3. è¯æ±‡è¡¨åŠ è½½")
        print("  4. åå¤„ç†æ­¥éª¤")
    
    print("\n" + "="*60)
    
    return 0 if (encoder_ok and decoder_ok) else 1


if __name__ == "__main__":
    sys.exit(main())
